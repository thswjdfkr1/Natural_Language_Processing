{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNfH5AOH5zDGQmTbdPhP8nX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i24I6KnBYkq1","executionInfo":{"status":"ok","timestamp":1741835494402,"user_tz":-540,"elapsed":4873,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"5a571e6c-fa75-4be7-8f3c-fe1dd7424098"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 1323k  100 1323k    0     0   631k      0  0:00:02  0:00:02 --:--:-- 1848k\n"]}],"source":["# @title 데이터준비\n","!mkdir my_data\n","\n","!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" > /dev/null\n","\n","!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" -o my_data/wiki_20190620_small.txt"]},{"cell_type":"code","source":["data = open('my_data/wiki_20190620_small.txt', 'r', encoding='utf-8')\n","lines = data.readlines()"],"metadata":{"id":"8vfpWa8cYpLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 어절 단위 토큰화\n","\n","text = \"이순신은 조선 중기의 무신이다.\"\n","tokenized_text = text.split(\" \")\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ss-8XZpZKvZ","executionInfo":{"status":"ok","timestamp":1741835494412,"user_tz":-540,"elapsed":6,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"22e80337-ee34-44e1-bbde-aa8f7c31a67c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신은', '조선', '중기의', '무신이다.']\n"]}]},{"cell_type":"code","source":["# @title 패딩\n","# 최대 길이를 정의해두고, 최대 길이 보다 길면 제거하고, 짧으면 의미가 없는 토큰을 추가\n","max_seq_length = 10\n","tokenized_text += [\"padding\"] * (max_seq_length - len(tokenized_text))\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm0EfinhZOGh","executionInfo":{"status":"ok","timestamp":1741835494420,"user_tz":-540,"elapsed":8,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"672498a3-6732-49ba-be4d-3e41a810e3dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신은', '조선', '중기의', '무신이다.', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding']\n"]}]},{"cell_type":"code","source":["# @title Tokenizer class\n","class Tokenizer:\n","  def __init__(self):\n","    self.tokenizer_type_list = ['word']\n","    self.pad_token = '<pad>'\n","    self.max_seq_length = 10\n","    self.padding = False\n","  def tokenize(self, text, tokenizer_type):\n","    assert tokenizer_type in self.tokenizer_type_list, \"None tokenizer type\"\n","    if tokenizer_type == 'word':\n","      tokenized_text = text.split(\" \")\n","    if self.padding:\n","      tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n","      return tokenized_text[:self.max_seq_length]\n","    else:\n","      return tokenized_text[:self.max_seq_length]\n","  def batch_tokenize(self, texts, tokenizer_type):\n","    for i, text in enumerate(texts):\n","      texts[i] = self.tokenize(text, tokenizer_type)\n","    return texts\n"],"metadata":{"id":"4qy4avSWaaSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_tokenizer = Tokenizer()\n","my_tokenizer.pad_token = '[pad]'\n","my_tokenizer.max_seq_length = 10\n","my_tokenizer.padding = True"],"metadata":{"id":"hxmfy02XbyW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'word'))\n","print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다\",'그는 임진왜란을 승리로 이끌었다'],'word'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lz6XX1KjcCdp","executionInfo":{"status":"ok","timestamp":1741835494456,"user_tz":-540,"elapsed":29,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"a249fdaf-f7fc-4e0f-8d21-ccd80b6b5ced"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신은', '조선', '중기의', '무신이다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n","[['이순신은', '조선', '중기의', '무신이다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]'], ['그는', '임진왜란을', '승리로', '이끌었다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']]\n"]}]},{"cell_type":"code","source":["# @title 형태소 단위 토큰화\n","\n","!sudo apt-get install build-essential\n","!sudo apt-get install python3-dev\n","!sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8\n","!pip install --upgrade pip setuptools wheel\n","\n","!pip install konlpy\n","!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"metadata":{"collapsed":true,"id":"ZQ4j0FT2cf8J","executionInfo":{"status":"ok","timestamp":1741835544677,"user_tz":-540,"elapsed":50220,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5d9ac1e3-1015-41df-ad03-7d7b73285562"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","python3-dev is already the newest version (3.10.6-1~22.04.1).\n","python3-dev set to manually installed.\n","0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libmecab2 mecab-ipadic mecab-utils\n","The following NEW packages will be installed:\n","  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n","0 upgraded, 6 newly installed, 0 to remove and 29 not upgraded.\n","Need to get 7,367 kB of archives.\n","After this operation, 59.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab2 amd64 0.996-14build9 [199 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab-dev amd64 0.996-14build9 [306 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-utils amd64 0.996-14build9 [4,850 B]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic all 2.7.0-20070801+main-3 [6,718 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mecab amd64 0.996-14build9 [136 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-3 [4,384 B]\n","Fetched 7,367 kB in 1s (8,876 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libmecab2:amd64.\n","(Reading database ... 124947 files and directories currently installed.)\n","Preparing to unpack .../0-libmecab2_0.996-14build9_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-14build9) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../1-libmecab-dev_0.996-14build9_amd64.deb ...\n","Unpacking libmecab-dev (0.996-14build9) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../2-mecab-utils_0.996-14build9_amd64.deb ...\n","Unpacking mecab-utils (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-3) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../4-mecab_0.996-14build9_amd64.deb ...\n","Unpacking mecab (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Setting up libmecab2:amd64 (0.996-14build9) ...\n","Setting up libmecab-dev (0.996-14build9) ...\n","Setting up mecab-utils (0.996-14build9) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-14build9) ...\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n","debconf: falling back to frontend: Readline\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.1.0)\n","Collecting setuptools\n","  Downloading setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n","Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.1.0\n","    Uninstalling setuptools-75.1.0:\n","      Successfully uninstalled setuptools-75.1.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pip-25.0.1 setuptools-76.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","setuptools"]},"id":"f36b11f271de43848d2489449134a20b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.1)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.2 konlpy-0.6.0\n","mecab-ko is already installed\n","Install mecab-ko-dic\n","Install mecab-ko-dic\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 47.4M  100 47.4M    0     0  22.6M      0  0:00:02  0:00:02 --:--:-- 42.3M\n","mecab-ko-dic-2.1.1-20180720/\n","mecab-ko-dic-2.1.1-20180720/configure\n","mecab-ko-dic-2.1.1-20180720/COPYING\n","mecab-ko-dic-2.1.1-20180720/autogen.sh\n","mecab-ko-dic-2.1.1-20180720/Place-station.csv\n","mecab-ko-dic-2.1.1-20180720/NNG.csv\n","mecab-ko-dic-2.1.1-20180720/README\n","mecab-ko-dic-2.1.1-20180720/EF.csv\n","mecab-ko-dic-2.1.1-20180720/MAG.csv\n","mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n","mecab-ko-dic-2.1.1-20180720/NNB.csv\n","mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n","mecab-ko-dic-2.1.1-20180720/VV.csv\n","mecab-ko-dic-2.1.1-20180720/Makefile.in\n","mecab-ko-dic-2.1.1-20180720/matrix.def\n","mecab-ko-dic-2.1.1-20180720/EC.csv\n","mecab-ko-dic-2.1.1-20180720/NNBC.csv\n","mecab-ko-dic-2.1.1-20180720/clean\n","mecab-ko-dic-2.1.1-20180720/ChangeLog\n","mecab-ko-dic-2.1.1-20180720/J.csv\n","mecab-ko-dic-2.1.1-20180720/.keep\n","mecab-ko-dic-2.1.1-20180720/feature.def\n","mecab-ko-dic-2.1.1-20180720/Foreign.csv\n","mecab-ko-dic-2.1.1-20180720/XPN.csv\n","mecab-ko-dic-2.1.1-20180720/EP.csv\n","mecab-ko-dic-2.1.1-20180720/NR.csv\n","mecab-ko-dic-2.1.1-20180720/left-id.def\n","mecab-ko-dic-2.1.1-20180720/Place.csv\n","mecab-ko-dic-2.1.1-20180720/Symbol.csv\n","mecab-ko-dic-2.1.1-20180720/dicrc\n","mecab-ko-dic-2.1.1-20180720/NP.csv\n","mecab-ko-dic-2.1.1-20180720/ETM.csv\n","mecab-ko-dic-2.1.1-20180720/IC.csv\n","mecab-ko-dic-2.1.1-20180720/Place-address.csv\n","mecab-ko-dic-2.1.1-20180720/Group.csv\n","mecab-ko-dic-2.1.1-20180720/model.def\n","mecab-ko-dic-2.1.1-20180720/XSN.csv\n","mecab-ko-dic-2.1.1-20180720/INSTALL\n","mecab-ko-dic-2.1.1-20180720/rewrite.def\n","mecab-ko-dic-2.1.1-20180720/Inflect.csv\n","mecab-ko-dic-2.1.1-20180720/configure.ac\n","mecab-ko-dic-2.1.1-20180720/NNP.csv\n","mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n","mecab-ko-dic-2.1.1-20180720/XSV.csv\n","mecab-ko-dic-2.1.1-20180720/pos-id.def\n","mecab-ko-dic-2.1.1-20180720/Makefile.am\n","mecab-ko-dic-2.1.1-20180720/unk.def\n","mecab-ko-dic-2.1.1-20180720/missing\n","mecab-ko-dic-2.1.1-20180720/VCP.csv\n","mecab-ko-dic-2.1.1-20180720/install-sh\n","mecab-ko-dic-2.1.1-20180720/Hanja.csv\n","mecab-ko-dic-2.1.1-20180720/MAJ.csv\n","mecab-ko-dic-2.1.1-20180720/XSA.csv\n","mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n","mecab-ko-dic-2.1.1-20180720/tools/\n","mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n","mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n","mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n","mecab-ko-dic-2.1.1-20180720/user-dic/\n","mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n","mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n","mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n","mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n","mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n","mecab-ko-dic-2.1.1-20180720/VX.csv\n","mecab-ko-dic-2.1.1-20180720/right-id.def\n","mecab-ko-dic-2.1.1-20180720/VA.csv\n","mecab-ko-dic-2.1.1-20180720/char.def\n","mecab-ko-dic-2.1.1-20180720/NEWS\n","mecab-ko-dic-2.1.1-20180720/MM.csv\n","mecab-ko-dic-2.1.1-20180720/ETN.csv\n","mecab-ko-dic-2.1.1-20180720/AUTHORS\n","mecab-ko-dic-2.1.1-20180720/Person.csv\n","mecab-ko-dic-2.1.1-20180720/XR.csv\n","mecab-ko-dic-2.1.1-20180720/VCN.csv\n","Looking in current directory for macros.\n","configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.\n","./lib/autoconf/general.m4:2434: AC_DIAGNOSE is expanded from...\n","aclocal.m4:139: AM_INIT_AUTOMAKE is expanded from...\n","configure.ac:2: the top level\n","configure.ac:56: warning: AC_OUTPUT should be used without arguments.\n","configure.ac:56: You should run autoupdate.\n","configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n","configure.ac:2: https://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n","checking for a BSD-compatible install... /usr/bin/install -c\n","checking whether build environment is sane... yes\n","/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n","Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n","configure: WARNING: 'missing' script is too old or missing\n","checking for a race-free mkdir -p... /usr/bin/mkdir -p\n","checking for gawk... no\n","checking for mawk... mawk\n","checking whether make sets $(MAKE)... yes\n","checking whether make supports nested variables... yes\n","checking for mecab-config... /usr/bin/mecab-config\n","checking that generated files are newer than configure... done\n","configure: creating ./config.status\n","config.status: creating Makefile\n","/usr/lib/x86_64-linux-gnu\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/usr/lib/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n","reading ./unk.def ... 13\n","emitting double-array: 100% |###########################################| \n","reading ./Place-address.csv ... 19301\n","reading ./Hanja.csv ... 125750\n","reading ./NNG.csv ... 208524\n","reading ./EC.csv ... 2547\n","reading ./Symbol.csv ... 16\n","reading ./EP.csv ... 51\n","reading ./CoinedWord.csv ... 148\n","reading ./EF.csv ... 1820\n","reading ./XSN.csv ... 124\n","reading ./ETM.csv ... 133\n","reading ./NNBC.csv ... 677\n","reading ./Person-actor.csv ... 99230\n","reading ./Place-station.csv ... 1145\n","reading ./IC.csv ... 1305\n","reading ./NP.csv ... 342\n","reading ./MM.csv ... 453\n","reading ./Preanalysis.csv ... 5\n","reading ./XR.csv ... 3637\n","reading ./VV.csv ... 7331\n","reading ./NNB.csv ... 140\n","reading ./J.csv ... 416\n","reading ./MAJ.csv ... 240\n","reading ./VA.csv ... 2360\n","reading ./VCN.csv ... 7\n","reading ./VX.csv ... 125\n","reading ./XSV.csv ... 23\n","reading ./MAG.csv ... 14242\n","reading ./NNP.csv ... 2371\n","reading ./VCP.csv ... 9\n","reading ./Group.csv ... 3176\n","reading ./Person.csv ... 196459\n","reading ./NorthKorea.csv ... 3\n","reading ./ETN.csv ... 14\n","reading ./XSA.csv ... 19\n","reading ./Place.csv ... 30303\n","reading ./Foreign.csv ... 11690\n","reading ./NR.csv ... 482\n","reading ./XPN.csv ... 83\n","reading ./Inflect.csv ... 44820\n","reading ./Wikipedia.csv ... 36762\n","emitting double-array: 100% |###########################################| \n","reading ./matrix.def ... 3822x2693\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","echo To enable dictionary, rewrite /etc/mecabrc as \\\"dicdir = /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic\\\"\n","To enable dictionary, rewrite /etc/mecabrc as \"dicdir = /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic\"\n","make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n","make[1]: Nothing to be done for 'install-exec-am'.\n"," /usr/bin/mkdir -p '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic'\n"," /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic'\n","make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n","Install mecab-python\n","/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n","Cloning into 'mecab-python-0.996'...\n","remote: Enumerating objects: 17, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 17 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (17/17), 59.67 KiB | 550.00 KiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n","/tmp/mecab-ko-dic-2.1.1-20180720\n","Processing /tmp/mecab-python-0.996\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mecab-python\n","  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mecab-python: filename=mecab_python-0.996-cp311-cp311-linux_x86_64.whl size=170228 sha256=4467d1379ca42fb50f8cc871252fc2f42b052de69e8d6c2d6a27f8f7e2a70e84\n","  Stored in directory: /root/.cache/pip/wheels/88/8a/ae/d85a9bb5b0f80513d485a3d9f3c74d015b6139f87476454e94\n","Successfully built mecab-python\n","Installing collected packages: mecab-python\n","Successfully installed mecab-python-0.996\n","Done.\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Mecab\n","\n","mecab = Mecab(dicpath=\"/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic\")\n","\n","print(mecab.pos(\"아버지가방에들어가신다\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WX-OFJ-5aOGh","executionInfo":{"status":"ok","timestamp":1741835544714,"user_tz":-540,"elapsed":28,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"3e2222bd-7908-492a-e9df-1cda07b28e32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('신다', 'EP+EC')]\n"]}]},{"cell_type":"code","source":["text = \"이순신은 조선 중기의 무신이다.\"\n","tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_UJUv1FcQXV","executionInfo":{"status":"ok","timestamp":1741835544727,"user_tz":-540,"elapsed":12,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"b62035b8-5b5d-4070-ff8b-c6e6a462e0a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.']\n"]}]},{"cell_type":"code","source":["# @title 형태소 Tokenizer class\n","class Tokenizer:\n","  def __init__(self):\n","    self.tokenizer_type_list = ['word','morph']\n","    self.pad_token = '<pad>'\n","    self.max_seq_length = 10\n","    self.padding = False\n","  def tokenize(self, text, tokenizer_type):\n","    assert tokenizer_type in self.tokenizer_type_list, \"None tokenizer type\"\n","    if tokenizer_type == 'word':\n","      tokenized_text = text.split(\" \")\n","    elif tokenizer_type =='morph':\n","      tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n","    if self.padding:\n","      tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n","      return tokenized_text[:self.max_seq_length]\n","    else:\n","      return tokenized_text[:self.max_seq_length]\n","  def batch_tokenize(self,texts, tokenizer_type):\n","    for i, text in enumerate(texts):\n","        texts[i] = self.tokenize(text, tokenizer_type)\n","    return texts\n"],"metadata":{"id":"ncc0DjpLcLHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_tokenizer = Tokenizer()\n","my_tokenizer.pad_token = '[pad]'\n","my_tokenizer.max_seq_length = 10\n","my_tokenizer.padding = True"],"metadata":{"id":"uaTXJQzGfZ86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'morph'))\n","print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"],'morph'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jr-4qzvhd5cA","executionInfo":{"status":"ok","timestamp":1741835544771,"user_tz":-540,"elapsed":24,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"911b1901-5cff-46e0-f3f3-46966a68ee31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '[pad]', '[pad]']\n","[['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.', '[pad]'], ['그', '는', '임진왜란', '을', '승리', '로', '이끌', '었', '다', '.']]\n"]}]},{"cell_type":"code","source":["# @title 음절 단위 토큰화"],"metadata":{"id":"xVhiTzhlfWpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"이순신은 조선 중기의 무신이다.\"\n","tokenized_text = list((text))\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdcbSLRZiLQQ","executionInfo":{"status":"ok","timestamp":1741835544778,"user_tz":-540,"elapsed":21,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"eb8192d0-164f-4f4f-fcc4-8ee0e3944d0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '.']\n"]}]},{"cell_type":"code","source":["# @title 자소단위 Tokenizer class\n","class Tokenizer:\n","  def __init__(self):\n","    self.tokenizer_type_list = ['word','morph','syllable']\n","    self.pad_token = '<pad>'\n","    self.max_seq_length = 10\n","    self.padding = False\n","  def tokenize(self, text, tokenizer_type):\n","    assert tokenizer_type in self.tokenizer_type_list, \"None tokenizer type\"\n","    if tokenizer_type == 'word':\n","      tokenized_text = text.split(\" \")\n","    elif tokenizer_type =='morph':\n","      tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n","    elif tokenizer_type == 'syllable':\n","      tokenized_text = list(text)\n","    if self.padding:\n","      tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n","      return tokenized_text[:self.max_seq_length]\n","    else:\n","      return tokenized_text[:self.max_seq_length]\n","  def batch_tokenize(self,texts, tokenizer_type):\n","    for i, text in enumerate(texts):\n","        texts[i] = self.tokenize(text, tokenizer_type)\n","    return texts\n"],"metadata":{"id":"nVZuqqL8iOQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_tokenizer = Tokenizer()\n","my_tokenizer.pad_token = '[pad]'\n","my_tokenizer.max_seq_length = 20\n","my_tokenizer.padding = True"],"metadata":{"id":"v0psxZLLiuBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'syllable'))\n","print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"],'syllable'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeIiHGRoiwIX","executionInfo":{"status":"ok","timestamp":1741835544827,"user_tz":-540,"elapsed":38,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"535fd7f5-e736-4eab-a879-188f120db19b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '[pad]', '[pad]', '[pad]', '[pad]']\n","[['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '.', '[pad]', '[pad]', '[pad]'], ['그', '는', ' ', '임', '진', '왜', '란', '을', ' ', '승', '리', '로', ' ', '이', '끌', '었', '다', '.', '[pad]', '[pad]']]\n"]}]},{"cell_type":"code","source":["# @title 자소 단위 토큰화\n","# 최대 초성, 중성, 종성 3개의 자소로 분리가 가능\n","\n","!pip install hgtk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkrxMugNi0aH","executionInfo":{"status":"ok","timestamp":1741835547810,"user_tz":-540,"elapsed":2984,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"8056cb96-c00c-4be1-8153-9c06c640f794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hgtk\n","  Downloading hgtk-0.2.1-py2.py3-none-any.whl.metadata (5.4 kB)\n","Downloading hgtk-0.2.1-py2.py3-none-any.whl (12 kB)\n","Installing collected packages: hgtk\n","Successfully installed hgtk-0.2.1\n"]}]},{"cell_type":"code","source":["import hgtk\n","\n","text = \"이순신은 조선 중기의 무신이다.\"\n","tokenized_text = list(hgtk.text.decompose(text))\n","print(tokenized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2D4MUYPYjhoJ","executionInfo":{"status":"ok","timestamp":1741835547838,"user_tz":-540,"elapsed":27,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"60e1ce17-1889-49b3-fb79-f218b8eb8773"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ', 'ㅓ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅜ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅁ', 'ㅜ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.']\n"]}]},{"cell_type":"code","source":["# @title 자소단위 Tokenizer class\n","class Tokenizer:\n","  def __init__(self):\n","    self.tokenizer_type_list = ['word','morph','syllable','jaso']\n","    self.pad_token = '<pad>'\n","    self.max_seq_length = 10\n","    self.padding = False\n","  def tokenize(self, text, tokenizer_type):\n","    assert tokenizer_type in self.tokenizer_type_list, \"None tokenizer type\"\n","    if tokenizer_type == 'word':\n","      tokenized_text = text.split(\" \")\n","    elif tokenizer_type =='morph':\n","      tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n","    elif tokenizer_type == 'syllable':\n","      tokenized_text = list(text)\n","    elif tokenizer_type == 'jaso':\n","      tokenized_text = list(hgtk.text.decompose(text))\n","    if self.padding:\n","      tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n","      return tokenized_text[:self.max_seq_length]\n","    else:\n","      return tokenized_text[:self.max_seq_length]\n","  def batch_tokenize(self,texts, tokenizer_type):\n","    for i, text in enumerate(texts):\n","        texts[i] = self.tokenize(text, tokenizer_type)\n","    return texts\n"],"metadata":{"id":"43gEaGjqjj0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_tokenizer = Tokenizer()\n","my_tokenizer.pad_token = '[pad]'\n","my_tokenizer.max_seq_length = 20\n","my_tokenizer.padding = True"],"metadata":{"id":"5V-7C2fXj7Ko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'jaso'))\n","print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"],'jaso'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jYDMJHnj9a3","executionInfo":{"status":"ok","timestamp":1741835547868,"user_tz":-540,"elapsed":6,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"86186d77-a454-4be7-a928-85b309fd17fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ']\n","[['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ'], ['ㄱ', 'ㅡ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅈ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅙ', 'ᴥ', 'ㄹ']]\n"]}]},{"cell_type":"code","source":["# @title Wordpiece 단위 토큰화\n","\n","\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3iV0v2qj_53","executionInfo":{"status":"ok","timestamp":1741835551248,"user_tz":-540,"elapsed":3379,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"69d7ed5b-2619-4cc2-a000-e0ca27ce1950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"]}]},{"cell_type":"code","source":["!mkdir wordPeiceTokenizer"],"metadata":{"id":"grhnI_e0kCDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tokenizers import BertWordPieceTokenizer\n","\n","wp_tokenizer = BertWordPieceTokenizer(\n","      clean_text= True,\n","      handle_chinese_chars= True,\n","      strip_accents= False,\n","      lowercase= False,\n",")\n","# clean_text를 True로 해주면, 토큰화시 띄워쓰기를 자동으로 제거\n","# handle_chinese_chars를 True로 해주면, 한자를 음절 단위로 처리\n","# strip_accents는 accent에 따라 자동으로 분리를 해주는 기능\n","# lowercase는 모든 알파벳을 소문자로 바꿔주는 기능"],"metadata":{"id":"Hkj9AwIEkLc4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wp_tokenizer.train(\n","      files=\"my_data/wiki_20190620_small.txt\",\n","      vocab_size=10000,\n","      min_frequency=2,\n","      show_progress=True,\n","      special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n","      wordpieces_prefix=\"##\"\n",")\n","\n","# vocab_size는 단어 사전의 크기. 단어 사전이 너무 크면 모두 음절 단위로 분리될 수 도 있음\n","# min_frequency는 정해진 개수 이하로 등장한 것은 사전에 추가하지 않을 수 있게 해줌\n","# show_progress는 처리 과정을 진행바로\n","# special_tokens는 앞서 배운 패딩과 같이 특수한 역할을 하는 토큰들을 의미\n","# wordpieces_prefix은 나눠진 글자가 하나라는 표시. (이순신 => 이, ##순신)\n","\n","print(wp_tokenizer.get_vocab_size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCsLHxwmllqg","executionInfo":{"status":"ok","timestamp":1741835982164,"user_tz":-540,"elapsed":1251,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"f2c1851f-f67d-4590-acae-c3034843fbde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n"]}]},{"cell_type":"code","source":["import os\n","\n","save_dir = \"wordPieceTokenizer\"\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)  # 디렉터리 생성\n","\n","wp_tokenizer.save_model(save_dir, \"my_tokenizer\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQQdl1UAgtAg","executionInfo":{"status":"ok","timestamp":1741835983576,"user_tz":-540,"elapsed":8,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"65a78756-bed6-4154-bb26-474b17d9047d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['wordPieceTokenizer/my_tokenizer-vocab.txt']"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["text = \"이순신은 조선 중기의 무신이다.\"\n","\n","tokenized_text = wp_tokenizer.encode(text)\n","print(tokenized_text)\n","print(tokenized_text.tokens)\n","print(tokenized_text.ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lt_5UyF3k_Bp","executionInfo":{"status":"ok","timestamp":1741835984934,"user_tz":-540,"elapsed":43,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"99c1037a-cf66-4f38-c3e5-b0c9dbe2d825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.']\n","[707, 1273, 7622, 2003, 755, 2607, 453, 8506, 1018, 16]\n"]}]},{"cell_type":"code","source":["# @title wordpiece Tokenizer class\n","class Tokenizer:\n","  def __init__(self):\n","    self.tokenizer_type_list = ['word','morph','syllable','jaso','wordpiece']\n","    self.pad_token = '<pad>'\n","    self.max_seq_length = 10\n","    self.padding = False\n","  def tokenize(self, text, tokenizer_type):\n","    assert tokenizer_type in self.tokenizer_type_list, \"None tokenizer type\"\n","    if tokenizer_type == 'word':\n","      tokenized_text = text.split(\" \")\n","    elif tokenizer_type =='morph':\n","      tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n","    elif tokenizer_type == 'syllable':\n","      tokenized_text = list(text)\n","    elif tokenizer_type == 'jaso':\n","      tokenized_text = list(hgtk.text.decompose(text))\n","    elif tokenizer_type == 'wordpiece':\n","      tokenized_text = wp_tokenizer.encode(text).tokens\n","    if self.padding:\n","      tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n","      return tokenized_text[:self.max_seq_length]\n","    else:\n","      return tokenized_text[:self.max_seq_length]\n","  def batch_tokenize(self,texts, tokenizer_type):\n","    for i, text in enumerate(texts):\n","        texts[i] = self.tokenize(text, tokenizer_type)\n","    return texts\n"],"metadata":{"id":"J43g4ce6ljXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_tokenizer = Tokenizer()\n","my_tokenizer.pad_token = '[pad]'\n","my_tokenizer.max_seq_length = 20\n","my_tokenizer.padding = True"],"metadata":{"id":"6kv50dIYnQ1n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'wordpiece'))\n","print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"],'wordpiece'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1T1kbJ0jnVV_","executionInfo":{"status":"ok","timestamp":1741835986459,"user_tz":-540,"elapsed":4,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"d4d78887-6036-42b4-af7a-5327180073eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n","[['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]'], ['그는', '임진', '##왜', '##란을', '승리', '##로', '이끌었다', '.', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']]\n"]}]},{"cell_type":"code","source":["# @title 구성된 함수 모두 확인\n","print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'word'))\n","print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'morph'))\n","print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'syllable'))\n","print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'jaso'))\n","print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다\",'wordpiece'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1T--14Fvnb5v","executionInfo":{"status":"ok","timestamp":1741835986910,"user_tz":-540,"elapsed":6,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"9a5bf62f-ea90-4b8b-ad8e-118072b89ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이순신은', '조선', '중기의', '무신이다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n","['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n","['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '[pad]', '[pad]', '[pad]', '[pad]']\n","['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ']\n","['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]', '[pad]']\n"]}]},{"cell_type":"markdown","source":["# BERT 학습"],"metadata":{"id":"4CTneWi1dojG"}},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"id":"3rlz1H-mogov","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741835987897,"user_tz":-540,"elapsed":4,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"32d94409-b0c7-49af-d050-12f3cfe14487"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["from transformers import BertConfig, BertForPreTraining, BertTokenizerFast"],"metadata":{"id":"V3onyodxesok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast(\n","    vocab_file = '/content/wordPieceTokenizer/my_tokenizer-vocab.txt',\n","    max_len = 128,\n","    do_lower_case=False,\n",")"],"metadata":{"id":"c-eMnjcDeupj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.add_special_tokens({'mask_token':'[MASK]'})\n","print(tokenizer.tokenize('이순신은 [MASK] 중기의 무신이다.'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKjf2cqkfFlu","executionInfo":{"status":"ok","timestamp":1741836154309,"user_tz":-540,"elapsed":7,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"0568e0be-4b43-4194-8fe2-54480270d508"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이', '##순', '##신은', '[MASK]', '중', '##기의', '무', '##신이', '##다', '.']\n"]}]},{"cell_type":"code","source":["config = BertConfig( # 영어기준\n","      vocab_size=20000,\n","      # hidden_size=512, # hidden vector size\n","      # num_hidden_layers=12, # layer num\n","      # num_attention_heads=8, # transformer attention head number\n","      # intermediate_size=3072, # transformer 내에 있는 feed-forward network의 dimension size\n","      # hidden_act=\"gelu\",\n","      # hidden_dropout_prob=0.1,\n","      # attention_probs_dropout_prob=0.1,\n","      max_position_embeddings=128, # embedding size 최대 몇 token까지 input으로 사용할 것인지 지정\n","      # type_vocab_size=2, # token type ids의 범위 (BERT는 segmentA, segmentB로 2종류)\n","      # pad_token_id=0,\n","      # position_embedding_type=\"absolute\"\n",")\n","model = BertForPreTraining(config=config)\n","model.num_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYYkmEvlhgcc","executionInfo":{"status":"ok","timestamp":1741836197382,"user_tz":-540,"elapsed":2519,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"a9bd76b3-8e28-4730-f145-e0245088067a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["101720098"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling"],"metadata":{"id":"0h9UP4oziN6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers.data.datasets.language_modeling import TextDatasetForNextSentencePrediction\n","\n","class TextDatasetForNextSentencePrediction(Dataset):"],"metadata":{"id":"2DloeBRJifgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","      tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"],"metadata":{"id":"593PlzUxhsZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments"],"metadata":{"id":"pisOepfckyQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","      output_dir='model_output',\n","      overwrite_output_dir=True,\n","      num_train_epochs=10,\n","      per_gpu_train_batch_size=32,\n","      save_steps=1000,\n","      save_total_limit=2,\n","      logging_steps=100\n",")\n","\n","# output_dir은 학습도중 모델이 저장될 위치\n","# overwrite_output_dir는 기존의 위치를 덮어써도 되는지를 설정\n","# num_train_epochs는 몇번 학습할지를 설정\n","# per_gpu_train_batch_size는 한번에 몇개의 데이터를 학습할지 결정"],"metadata":{"id":"B3xpvgN-kztN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","      model=model,\n","      args=training_args,\n","      data_collator=data_collator,\n","      train_dataset=dataset\n",")\n","trainer.train()"],"metadata":{"id":"KaMXWS7pk0pZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForMaskedLM, pipeline\n","\n","my_model = BertForMaskedLM.from_pretrained('model_output')\n","nlp_fill = pipeline('fill-mask', top_k=5, model=my_model, tokenizer=tokenizer)\n","nlp_fill('이순신은 [MASK] 중기의 무신이다.')"],"metadata":{"id":"_5K5ziiPk5T5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qxevhEFulEWh"},"execution_count":null,"outputs":[]}]}